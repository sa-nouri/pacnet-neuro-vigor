{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aSCP00vRQMpC"},"outputs":[],"source":["#@title Mount drive files\n","from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1QZLjhjQvjK"},"outputs":[],"source":["import cv2\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from IPython.display import Image, display\n","from tensorflow import keras\n","from tensorflow.keras.utils import array_to_img, img_to_array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTYFlM65SmpZ"},"outputs":[],"source":["model = tf.keras.applications.ResNet101()\n","preprocess_input = keras.applications.resnet.preprocess_input\n","decode_predictions = keras.applications.resnet.decode_predictions\n","\n","IMG_SIZE = (224, 224, 3)\n","NUM_CLASSES = 1000\n","LAST_CONV_LAYER_NAME = 'conv5_block3_out'\n","\n","# data.iloc[8232] # pdoffmed\n","# data.iloc[10994] # pdonmed\n","# data[data['task_data'] == 'pdonmed']\n","# data[data['eeg_data'] == 'shampd1eeg'] # 3737\n","# data[data['eeg_data'] == 'stim7pd2eeg'] # 9244\n","# data[data['eeg_data'] == 'stim8pd1eeg'] # 14424"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m8mHbE12ZqB7"},"outputs":[],"source":["path_pacs_dataset = \"/path-to-pacs-dir/\"\n","df = pd.read_parquet(path_pacs_dataset + \"data_merged.parquet\")\n","df.drop_duplicates(subset=['task', 'stimulus', 'medication', 'channel', 'subject', 'trial'], \n","                    keep='first', inplace=True, ignore_index=True)\n","df = df.dropna(subset=[\"peak_time\", \"reaction_time\"])\n","print(df.info())\n","print(df)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"McXR0NClqq3l","tags":[]},"source":["### Randomly selected data for Grad-CAM\n","\n","*\n","11 - hcoff - sham;\n","6154 - hcoff - stim7;\n","10110 - hcoff - stim8;\n","\n","*\n","17944 - pdoff - sham;\n","19838 - pdoff - stim7;\n","26315 - pdoff - stim8;\n","\n","*\n","29282 - pdon - sham;\n","34586 - pdon - stim7;\n","39684 - pdon - stim8;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NR3ib75jvp_Y"},"outputs":[],"source":["pac = df[\"pac_values\"].iloc[11]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TmIu9DYv8S9"},"outputs":[],"source":["array = img_to_array(array_to_img(pac.reshape(60, 30, 1), scale=False).resize((224, 224)))\n","array = np.dstack([array] * 3)\n","array = np.expand_dims(array, axis=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QXnLa2BVqG36"},"source":["# Grad-**CAM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpOExAhffm4W"},"outputs":[],"source":["def get_img_array(pac_w, size=(224, 224, 3)):\n","\n","    array = img_to_array(array_to_img(pac_w.reshape(60, 30, 1), scale=False).resize((224, 224)))\n","    array = np.dstack([array] * 3)\n","    array = np.expand_dims(array, axis=0)\n","    return array\n","\n","def make_gradcam_heatmap(img_array, model, LAST_CONV_LAYER_NAME, pred_index=None):\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(LAST_CONV_LAYER_NAME).output, model.output])\n","\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgwRecRpfy40"},"outputs":[],"source":["img_array = preprocess_input(get_img_array(pac, size=IMG_SIZE))\n","model.layers[-1].activation = None\n","preds = model.predict(img_array)\n","print(\"Predicted:\", decode_predictions(preds, top=2)[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjrjhNi7gKxO"},"outputs":[],"source":["def save_and_display_gradcam(pac_w, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n","\n","    img = img_to_array(array_to_img(pac_w.reshape(60, 30, 1), scale=False).resize((224, 224)))\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    jet = cm.get_cmap(\"jet\")\n","\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","\n","    superimposed_img = jet_heatmap * alpha + img\n","    data = img_to_array(array_to_img(superimposed_img, scale=False).resize((30, 60)))\n","    superimposed_img = array_to_img(superimposed_img)\n","\n","    superimposed_img.save(cam_path)\n","\n","    display(Image(cam_path))\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ze6o18DS5JLx"},"outputs":[],"source":["heatmap = make_gradcam_heatmap(img_array, model, LAST_CONV_LAYER_NAME, pred_index=260)\n","\n","plt.matshow(heatmap)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOuMEI68c3hx"},"outputs":[],"source":["heatmap = make_gradcam_heatmap(img_array, model, LAST_CONV_LAYER_NAME, pred_index=285)\n","m = save_and_display_gradcam(pac, heatmap)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OD4cY5eK7WGt"},"outputs":[],"source":["path_sm = \"/path-to-results-saliency-maps/\"\n","np.save(path_sm + \"saliency_h1.npy\", m) \n","print(m.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ngGGSHKT-vfP"},"outputs":[],"source":["x = np.load(path_sm + \"saliency_h1.npy\")\n","print(np.median(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBrhYop6tyjJ"},"outputs":[],"source":["heatmap = make_gradcam_heatmap(img_array, model, LAST_CONV_LAYER_NAME, pred_index=1)\n","save_and_display_gradcam(pac, heatmap)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0b71Gof9eSxp"},"source":["# Guided Grad-CAM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjQR9uqEM_1P"},"outputs":[],"source":["@tf.custom_gradient\n","def guided_relu(x):\n","    def grad(dy):\n","        return tf.cast(dy > 0, \"float32\") * tf.cast(x > 0, \"float32\") * dy\n","    return tf.nn.relu(x), grad\n","\n","class GuidedBackprop:\n","    def __init__(self, model):\n","        self.model = model\n","        self.gb_model = self.build_guided_model()\n","\n","    def build_guided_model(self):\n","        # build a guided version of the model replace ReLU with guided ReLU\n","        gb_model = tf.keras.Model(\n","            self.model.inputs, self.model.output\n","        )\n","        layers = [\n","            layer for layer in gb_model.layers[1:] if hasattr(layer, \"activation\")\n","        ]\n","        for layer in layers:\n","            if layer.activation == tf.keras.activations.relu:\n","                layer.activation = guided_relu\n","        return gb_model\n","\n","    def guided_backprop(self, image: np.ndarray, class_index: int):\n","        expected_output = tf.one_hot([class_index] * image.shape[0], NUM_CLASSES)\n","        with tf.GradientTape() as tape:\n","            inputs = tf.cast(image, tf.float32)\n","            tape.watch(inputs)\n","            outputs = self.gb_model(inputs)\n","            loss = tf.keras.losses.categorical_crossentropy(\n","                expected_output, outputs)\n","        grads = tape.gradient(loss, inputs)[0]\n","        return grads"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYi4Hjc3xwpe"},"outputs":[],"source":["model = tf.keras.applications.ResNet101()\n","gb = GuidedBackprop(model)\n","\n","saliency_map = gb.guided_backprop(img_array, class_index=100).numpy()\n","\n","# Normalize with mean 0 and std 1\n","saliency_map -= saliency_map.mean()\n","saliency_map /= saliency_map.std() + tf.keras.backend.epsilon()\n","# Change mean to 0.5 and std to 0.25\n","saliency_map *= 0.25\n","saliency_map += 0.5\n","# Clip values between 0 and 1\n","saliency_map = np.clip(saliency_map, 0, 1)\n","# Change values between 0 and 255\n","saliency_map *= (2 ** 8) - 1\n","saliency_map = saliency_map.astype(np.uint8)\n","\n","plt.axis('off')\n","plt.imshow(saliency_map)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9aqj0ehNAmc"},"outputs":[],"source":["gb = GuidedBackprop(model)\n","\n","# Guided grad_cam is guided backpropogation with feature importance coming from grad-cam\n","saliency_map = gb.guided_backprop(img_array, class_index=260).numpy()\n","gradcam = cv2.resize(heatmap, (224, 224))\n","gradcam = np.clip(gradcam, 0, np.max(gradcam)) / np.max(gradcam)\n","guided_gradcam = saliency_map * np.repeat(gradcam[..., np.newaxis], 3, axis=2)\n","\n","# Normalize\n","guided_gradcam -= guided_gradcam.mean()\n","guided_gradcam /= guided_gradcam.std() + tf.keras.backend.epsilon()\n","guided_gradcam *= 0.25\n","guided_gradcam += 0.5\n","guided_gradcam = np.clip(guided_gradcam, 0, 1)\n","guided_gradcam *= (2 ** 8) - 1\n","guided_gradcam = guided_gradcam.astype(np.uint8)\n","\n","plt.axis('off')\n","plt.imshow(guided_gradcam)"]}],"metadata":{"colab":{"collapsed_sections":["QXnLa2BVqG36","0b71Gof9eSxp"],"provenance":[{"file_id":"https://github.com/SalarNouri/PAC-Exploration/blob/main/pac_image/CNN_Interpretation.ipynb","timestamp":1664292999963}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
